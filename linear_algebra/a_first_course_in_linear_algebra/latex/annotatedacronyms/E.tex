%%%%(c)
%%%%(c)  This file is a portion of the source for the textbook
%%%%(c)
%%%%(c)    A First Course in Linear Algebra
%%%%(c)    Copyright 2004 by Robert A. Beezer
%%%%(c)
%%%%(c)  See the file COPYING.txt for copying conditions
%%%%(c)
%%%%(c)
%%%%%%%%%%%
%%
%%  Annotated Acronyms E
%%  Determinants
%%
%%%%%%%%%%%
%
\annoacro{theorem}{EMRCP}{%
Much of what we know about eigenvalues can be traced to analysis of the characteristic polynomial.  When we first defined eigenvalues, you might have wondered if they were scarce, or abundant.  The characteristic polynomial allows us to answer a question like this with a result like \acronymref{theorem}{NEM} which tells us there are always a few eigenvalues, but never too many.
}
%
\annoacro{theorem}{EMNS}{%
If \acronymref{theorem}{EMRCP} allows us to learn about eigenvalues through what we know about roots of polynomials, then \acronymref{theorem}{EMNS} allows us to learn about eigenvectors, and eigenspaces, from what we already know about null spaces.  These two theorems, along with \acronymref{definition}{EEM}, provide the starting points for discerning the properties of eigenvalues and eigenvectors (to say nothing of actually computing them).
}
%
\annoacro{theorem}{HMRE}{%
As we have remarked before, we choose to include all of the complex numbers in our set of allowed scalars, whereas many introductory texts restrict their attention to just the real numbers.  Here is one of the payoffs to this approach.  Begin with a matrix, possibly containing complex entries, and require the matrix to be Hermitian (\acronymref{definition}{HM}).  In the case of only real entries, this boils down to just requiring the matrix to be symmetric (\acronymref{definition}{SYM}).  Generally, the roots of a characteristic polynomial, even with all real coefficients, can have complex numbers as roots.  But for a Hermitian matrix, all of the eigenvalues are real numbers!  When somebody tells you mathematics can be beautiful, this is an example of what they are talking about.
}
%
\annoacro{theorem}{DC}{%
Diagonalizing a matrix, or the question of if a matrix is diagonalizable, could be viewed as one of a handful of central questions in linear algebra.  Here we have an unequivocal answer to the question of ``if,'' along with a proof containing a construction for the diagonalization.  So this theorem is of theoretical and computational interest.  This topic will be important again in \acronymref{chapter}{R}.
}
%
\annoacro{theorem}{DMFE}{%
Another unequivocal answer to the question of if a matrix is diagonalizable, with perhaps a simpler condition to test.  The proof also tells us how to construct the necessary set of $n$ linearly independent eigenvectors --- just round up bases for each eigenspace and join them together.  No need to test the linear independence of the combined set.
}
%
% End E.tex annotated acronyms
